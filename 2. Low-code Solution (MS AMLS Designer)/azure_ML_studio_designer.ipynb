{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54J22hlOiz3y"
   },
   "source": [
    "**Author** : V.Joan Aléonard<br>\n",
    "**Last update** :  5 May 2021<br>\n",
    "**OC English path** : https://openclassrooms.com/fr/paths/167-ai-engineer#path-tabs<br>\n",
    "**OC French path** : https://openclassrooms.com/fr/paths/188-ingenieur-ia#path-tabs<br>\n",
    "**Title** : **Use Deep Learning to detect Bad Buzz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NoIPCvoi3A5"
   },
   "source": [
    "![air-paradis](https://drive.google.com/uc?id=1T26mpOAUvJP700W4m8bjfYCLmDYVcyJL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXPqk-gZi6rv"
   },
   "source": [
    "# <font color=red><center>**AIR PARADIS**</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cXAbfKgi79d"
   },
   "source": [
    "**Air Paradis** is an airline company that wants to use AI (*Artificial Intelligence*) to **detect Bad Buzz associated with its brand** in online public tweets.\n",
    "\n",
    "**As AI engineer for Marketing Intelligence Consulting**, we will dive into **NLP** (*Natural Language Processing*) techniques to serve Air Paradis' purpose.\n",
    "\n",
    "Indeed, NLP allows a machine to **understand and process human language**. It will help us to solve this **text classification goal** and **detect sentiment** (positive or negative) from these tweets.\n",
    "\n",
    "We will deploy our best **DETECT SENTIMENT solution** through <font color=salmon>**Microsoft Azure Machine Learning plateform**</font> (***MS Azure ML***).\n",
    "\n",
    "<br>\n",
    "\n",
    "Therefore, we will structure the project as follows:\n",
    "\n",
    "<br>\n",
    "\n",
    "| **Services / Tools** | **Objective** | **Available notebook** |\n",
    "| :-- | :-- | :-- |\n",
    "| **Google Colab and Python libraries** | Build quality of data by pre-processing the tweets text | Notebook N°1 |\n",
    "| **Google Colab / MS Azure Cognitive Services API** | Use Text Analytics > Sentiment API | Notebook N°2 |\n",
    "| **Python Script / MS Azure ML Studio > Designer** | Use \"Drag-and-Drop\" pipeline with no code in Azure ML Studio| **<font color=green>Notebook N°3</font>** |\n",
    "| **Tensorflow-Keras / Google Colab PRO with GPU/TPU** | Train and evaluate advanced models | Notebook N°4 |\n",
    "| **MS Azure ML Cloud > Models** | Deploy the best solution in MS Azure WebService | Notebook N°5 |\n",
    "\n",
    "<br>\n",
    "\n",
    "This notebook is dedicated to 3rd task : **test Azure Machine Learning Studio Designer to build and train a logistic regression model as Sentiment classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlHJhoP2jaX6"
   },
   "source": [
    "# <font color=brown><center>**NOTEBOOK 3<br>AZURE MACHINE LEARNING STUDIO<br>LOGISTIC REGRESSION PIPELINE**</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeFrdABRkU9f"
   },
   "source": [
    "![aml-studio](https://drive.google.com/uc?id=1H-cir-dzjvvU8ggTfmVcILDtLmAD_mfL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pYNT_Ak8r6U"
   },
   "source": [
    "# <font color=salmon>PART 1 - AZURE MACHINE LEARNING STUDIO</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D41GDNGK8x-b"
   },
   "source": [
    "## <font color=green>P1.1 - Understand Azure ML Studio</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsEZWYC61q1E"
   },
   "source": [
    "**Azure Machine Learning** is a cloud-based environment that can be used to **train, deploy, automate, manage, and track ML models**.\n",
    "\n",
    "**Azure Machine Learning Studio** is a web portal in Azure Machine Learning for **low-code and no-code options** for model training, deployment, and asset management:\n",
    "- **Notebooks**, directly integrated to write and run our own code in managed Jupyter Notebook servers;\n",
    "- **Designer**, with Drag-and-drop interface to train and deploy machine learning models as *pipeline*, with low or no-code;\n",
    "- **Experiment**, to diagnose errors and warnings, or track performance metrics of experiments scaled with compute target;\n",
    "- **Compute**, to manage a wide and customizable range of compute ressources.\n",
    "\n",
    "The documentation about Azure ML Studio can be found [here](https://ml.azure.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnvIh_Ve8ZMx"
   },
   "source": [
    "![designer](https://drive.google.com/uc?id=1ZCh32XNfGvUIfqR8DNZNdhQCsODuWda7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUQTryr_rQNI"
   },
   "source": [
    "An **AML workplace** is necessary to interact with AML Studio.\n",
    "\n",
    "This workplace is the centralized place which contains all the components that allows us to create, use and register any of Azure Machine Learning resources.\n",
    "\n",
    "The documentation about the workspace can be found [here](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcxYL9lM_k2A"
   },
   "source": [
    "## <font color=green>P1.2 - Understand Azure ML Designer</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf7O6wRgNOsY"
   },
   "source": [
    "As said previously, the **Designer** is a **drag-and-drop** tool used to create machine learning models with no code or low code.\n",
    "\n",
    "In the Designer interface, Azure Machine Learning Studio gives 2 options:\n",
    "- **Create from scratch a new pipeline**;\n",
    "- **Clone one of the available sample pipelines** and adapt it to our need.\n",
    "\n",
    "We have chosen the 2nd option: \n",
    "- Clone the **Text Classification - Wikipedia SP 500 Dataset** sample;\n",
    "- Adapt the easy-to-use prebuilt modules to our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JELe6Ve6AItE"
   },
   "source": [
    "![create](https://drive.google.com/uc?id=1LqldFiaoermnqOGUCZsFswIZj_AHqQdX)![sample](https://drive.google.com/uc?id=1raMo5WgLn-eapEpvlsolO050KO231e41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLv__zXBTdss"
   },
   "source": [
    "## <font color=green>P1.3 - Understand pipeline steps and modules</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmVLh2-4V8r0"
   },
   "source": [
    "The pipeline is a **series of steps called \"modules\", connected to each other in order to build a complete workflow of a machine learning task**.\n",
    "\n",
    "A **module** is an algorithm that can be performed on the data, such as:\n",
    "- **Data preparation**: dataset importation, sampling, data cleaning;\n",
    "- **Data transformation**: hashing and n-grams features from text;\n",
    "- **Data split in subsets**: train and test sets;\n",
    "- **Model selection**: regression, classification;\n",
    "- **Training configuration**: especially, compute resources;\n",
    "- **Progress monitoring**: errors and warning diagnosis, performance tracking,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlgKymqWv_4n"
   },
   "source": [
    "![homepage](https://drive.google.com/uc?id=1B-8y-l9dN15O8Cq-P7iE_9twziF18qKM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCt5ESvs89Hb"
   },
   "source": [
    "# <font color=salmon>PART 2 - WORK WITH CLONED PIPELINE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KvxBuWssaLg"
   },
   "source": [
    "## <font color=green>P2.1 - Create dataframe sample</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qr0cqJ8YxbOd"
   },
   "source": [
    "First we need to create a sample dataframe to replace the \"Wikipedia SP 500 Dataset\" in the pipeline.\n",
    "\n",
    "As seen in our first notebook, the text that has the best performance is **cleaned_tweet**, which have been pre-processed but have kept stopwords, and are not lemmatized.\n",
    "\n",
    "We will use to keep all our models **comparable**, with roughly same variables to appy, except sample size and some little variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hJ692U80xwtS"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Set environment and tools configuration\n",
    "src_folder = Path('/content/drive/MyDrive/OC_IA/P07')\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "YySOpsdTxuVL",
    "outputId": "447d0d32-97de-4e95-ffe9-31cd6bf8d13b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE dimension:  (30000, 2)\n",
      "SENTIMENT distribution: \n",
      " 1    15000\n",
      "0    15000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad that i have been gone for a week missing my puppy and tomorrow i have to leave again for a week</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have a sore throat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is so extremely tired and dosent want to go to school today</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user eh up you we are talking saab se estate too had to get a t as insurance would not touch poppet on a t</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user thanks for the opinion dougie ha ha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  clean_tweet  sentiment\n",
       "0         sad that i have been gone for a week missing my puppy and tomorrow i have to leave again for a week          0\n",
       "1                                                                                        i have a sore throat          0\n",
       "2                                                 is so extremely tired and dosent want to go to school today          0\n",
       "3  user eh up you we are talking saab se estate too had to get a t as insurance would not touch poppet on a t          0\n",
       "4                                                                    user thanks for the opinion dougie ha ha          0"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pre-processed data\n",
    "df = pd.read_csv(src_folder / 'p7_01b_final_df.csv')\n",
    "\n",
    "# Drop useless features\n",
    "df = df.drop(columns=['user', 'tweet', 'clean_w_count', 'noStop_tweet',\n",
    "                      'lemma_tweet', 'lemma_w_count'])\n",
    "\n",
    "# Define the number of observation per classe (positive / negative)\n",
    "N_SENTIMENT = 15000 #@param [\"10000\", \"15000\", \"25000\"] {type:\"raw\"}\n",
    "\n",
    "# Create a sample of DF\n",
    "sample_df = df.groupby('sentiment').apply(lambda x: x.sample(n=N_SENTIMENT,\n",
    "                                                             random_state=42))\n",
    "sample_df.reset_index(drop=True, inplace=True)\n",
    "sample_df = sample_df[['clean_tweet', 'sentiment']]\n",
    "\n",
    "# Display DF main info\n",
    "print('SAMPLE dimension: ', sample_df.shape)\n",
    "print('SENTIMENT distribution: \\n', sample_df.sentiment.value_counts())\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jOcI5BjN7kMn"
   },
   "outputs": [],
   "source": [
    "# Save to csv file\n",
    "sample_df.to_csv(src_folder / 'p7_03_sample_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyqRIDbD7tF0"
   },
   "source": [
    "Well, we have saved our sample data to disk.\n",
    "\n",
    "Let's get to AML Studio to load it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNprOgDaUOlE"
   },
   "source": [
    "## <font color=green>P2.2 - Clone existing pipeline</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9ehM9j-rzRS"
   },
   "source": [
    "![amls-clone](https://drive.google.com/uc?id=1Frok4zJLGvslMK-AnfSjmJdHP1HbIg_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFpHaU-JA5Zd"
   },
   "source": [
    "When we click on **Designer** in the left menu, we know have a copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QipuzKgyBA5Z"
   },
   "source": [
    "![get](https://drive.google.com/uc?id=1t_-Bn16F5G9_a3aLlXyFE9AyxCpCtpam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M43BBHYw8mDb"
   },
   "source": [
    "## <font color=green>P2.3 - Register our sample dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8wLkN9f8-Vb"
   },
   "source": [
    "Then, we go to AML Studio again and choose **Datasets** in the left menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2U24aKLl8z9s"
   },
   "source": [
    "![dataset](https://drive.google.com/uc?id=11zCfJDfO354Q29e3EIo1Nfh36doObZXU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4-S4ASM9NKc"
   },
   "source": [
    "![get](https://drive.google.com/uc?id=1xG06Pj1J35TN1ckQuVF2dsWvObugSLG7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfYKm2O4CGdQ"
   },
   "source": [
    "## <font color=green>P2.4 - Adapt cloned pipeline</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYIzCcNlDymz"
   },
   "source": [
    "### <font color=blue>P2.4.1 - 1st step : change the dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYUp-_OuEAL9"
   },
   "source": [
    "We just need to click on the module of the old dataset (Wikipedia), delete it and drag-and-drop the new dataset.\n",
    "\n",
    "Eventually, we can change some parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqYh55chDy_Z"
   },
   "source": [
    "![change](https://drive.google.com/uc?id=11w7NFTV0_XwagKGPbZnWiTs0EW9ijTjD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzPyyXuREvTa"
   },
   "source": [
    "### <font color=blue>P2.4.2 - Following steps : adjust the parameters of other modules</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xm6_h0ijE3g-"
   },
   "source": [
    "The following actions have been done:\n",
    "- **Preprocess Text** has been removed as we do want the model to predict on our cleaned tweet;\n",
    "- **Split Data** has been re-ajusted to 0.8 Train set and 0.2 Test set, add a Random seed (42), keep the data with *stratified split*;\n",
    "- We have changed the model from *Multiclass Logistic Regression* to **Two-Class Logistic Regression** with random seed = 42, as classification algorithm.\n",
    "\n",
    "In the cloned pipeline, 2 models of Text Data transformation are used:\n",
    "- Feature Hashing;\n",
    "- Extract N-Gram Features from Text.\n",
    "\n",
    "The unique parameter we have changed for both is *Target column* to match our cleaned tweet.\n",
    "\n",
    "The rest was kept inchanged : **Train Model, Score Model, Evaluate Model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bnhH-q_LsMB"
   },
   "source": [
    "![pipe](https://drive.google.com/uc?id=1M6ubhDJtXPsse1G0IETV6b65TnORp4xN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp3rBF6IL3m2"
   },
   "source": [
    "## <font color=green>P2.5 - Set up compute target</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaW-gloqMFDc"
   },
   "source": [
    "Here again, we have 2 choices to create a compute target:\n",
    "- Create one with the predefined configuration;\n",
    "- Create a compute cluster ==> this is the option we took."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pe8r1yvMPCfM"
   },
   "source": [
    "![predefined](https://drive.google.com/uc?id=1e6dOgNY1w9-P1QuGVVPddOMCZU22wSWx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lOphalFPC07"
   },
   "source": [
    "![cluster](https://drive.google.com/uc?id=1ndCBlGH5Xj43BMO3wb2FBwx4y4AP22UP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqwQPHqLRiby"
   },
   "source": [
    "## <font color=green>P2.5 - Set up pipeline run and submit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cdc8YJQodv4"
   },
   "source": [
    "We just have to create the experiment by giving a name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bc2mo9LoRtc"
   },
   "source": [
    "![submit](https://drive.google.com/uc?id=1_0i5C3cYXUekaCF7BCT65WwAyolgrQRL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxjknAOh8TNw"
   },
   "source": [
    "<font color=red>And we wait BUT we encountered a lot of hiccups and we had to run 64 submissions before we got a result!</font>.\n",
    "\n",
    "This is not what I would qualify of an **\"easy drag-and-drop\"** tool, but it's a personal opinion.\n",
    "\n",
    "Besides, it requires a minimum of understanding of how each algorithm is working - in terms of input and output requirements or parameters, to be able to debug when the runs of each module fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ofuTvpO8Cyl"
   },
   "source": [
    "![run](https://drive.google.com/uc?id=1tt_P7xrHRwrMe5rpGPYsYnvwlsvlpcPB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOt9L9jH8wsb"
   },
   "source": [
    "## <font color=green>P2.6 - Evaluate the result</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_CbCbBQ5ASd"
   },
   "source": [
    "\n",
    "As we have split our 30k data to 0.8% Train and 0.2% Test, the evaluation was made on 6k data rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8FuefgN5Z0z"
   },
   "source": [
    "### <font color=blue>P2.6.1 - Evaluate feature hashing (left port)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaBl8rb156WU"
   },
   "source": [
    "**Feature Hashing** module transforms a stream of English text into a set of integer features.\n",
    "\n",
    "It operates on the exact **strings** provided as input and does not perform any linguistic analysis or preprocessing.\n",
    "\n",
    "Internally, the Feature Hashing module creates a dictionary of n-grams, the size of the n-grams can be controled by using the N-grams property.\n",
    "\n",
    "After the dictionary is built, the Feature Hashing module converts the dictionary terms into hash values. It then computes whether a feature was used in each case. For each row of text data, the module outputs a set of columns, one column for each hashed feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMs-MkaI-kH1"
   },
   "source": [
    "#### **Visualize transformed dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xZi4Ub5-5u4"
   },
   "source": [
    "![dataset](https://drive.google.com/uc?id=1y7f-K_mXDAVmKUlYW5GZy1noPORdgGf-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SseuyUTi-qHF"
   },
   "source": [
    "#### **Visualize metrics and confusion matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOOnxMJWyGgY"
   },
   "source": [
    "***Observations***:\n",
    "- First, we note that the confusion matrix is not plotted as usual, that means, it is structured differently: the actual values are in the top (abscissa) and the predicted values are in the left (ordinate); besides, positive value (1) is given first; in the figure, the True Positives are in the top-left box, and the True Negatives are in the bottom-right box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux5OWgT-BR9l"
   },
   "source": [
    "![left](https://drive.google.com/uc?id=1Mce8cH5mVp6PR04-RQIV-vXPaaeaA_s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6iF5CiSW97Iu"
   },
   "source": [
    "<font color=red>**Note that the model has its best accuracy (0.704) at 0.52 classification threshold.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mitXfvV7DIv"
   },
   "source": [
    "### <font color=blue>P2.6.2 - Evaluate n-gram extraction features from text (right port)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31zqgOwwACnd"
   },
   "source": [
    "The **Extract N-Gram Features from Text** module *featurizes* unstructured text data. \n",
    "\n",
    "It creates a new list of n-grams from dictionary provided by the processed column of raw text: for example, if the N-Gram size is 2, unigrams and bigrams will be created.\n",
    "\n",
    "The <code>**weighting function**</code> was set to **TF-IDF Weight**, that means, that, *term frequency/inverse document frequency (TF/IDF) score* is assigned to the extracted n-grams. The value for each n-gram is its TF score multiplied by its IDF score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_3NlTRh-0T7"
   },
   "source": [
    "#### **Visualize transformed dataset and vocabulary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN8aBrbU_jYo"
   },
   "source": [
    "![dataset](https://drive.google.com/uc?id=1MqjSdU88ZcWwBIQk6wu06yArJXhhRhUN) ![vocab](https://drive.google.com/uc?id=1KIeHGC8kOsljizwOzyCMAnNh9MSJtGGZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ECjgo1T-0T8"
   },
   "source": [
    "#### **Visualize metrics and confusion matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6DmhhMJBjZr"
   },
   "source": [
    "![right](https://drive.google.com/uc?id=1m4d58QP_IfE71MvnQTjPyHiCxwEUBrYV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xYnUdmZ-MNZ"
   },
   "source": [
    "<font color=red>**Note that the model has its best accuracy (0.764) at 0.48 classification threshold.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYyL0bbaF2KE"
   },
   "source": [
    "The result can be summarized as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "qXpWmonWUcdC",
    "outputId": "8aa97332-54ba-47ba-dd42-945995b5b7ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predict_time</th>\n",
       "      <th>AUC_Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Studio - Feat. hashing</td>\n",
       "      <td>81.5</td>\n",
       "      <td>76.900%</td>\n",
       "      <td>70.000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Studio - N-grams extraction</td>\n",
       "      <td>103.4</td>\n",
       "      <td>84.200%</td>\n",
       "      <td>76.300%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model Predict_time AUC_Score Accuracy\n",
       "0       Studio - Feat. hashing         81.5   76.900%  70.000%\n",
       "1  Studio - N-grams extraction        103.4   84.200%  76.300%"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create empty list\n",
    "scores_model = []\n",
    "\n",
    "# Append scores/results\n",
    "scores_model.append({'Model': 'Studio - Feat. hashing',\n",
    "                     'Predict_time':'{:0.1f}'.format(60+21.45),\n",
    "                     'AUC_Score':'{:0.3f}%'.format(76.9),\n",
    "                     'Accuracy':'{:0.3f}%'.format(70.0)})\n",
    "\n",
    "# Save in DF\n",
    "model_results = pd.DataFrame.from_records(scores_model)\n",
    "\n",
    "# Append scores/results\n",
    "model_results = model_results.append({'Model': 'Studio - N-grams extraction',\n",
    "                                      'Predict_time':'{:0.1f}'.format(60+43.43),\n",
    "                                      'AUC_Score':'{:0.3f}%'.format(84.2),\n",
    "                                      'Accuracy':'{:0.3f}%'.format(76.3)},\n",
    "                                     ignore_index=True)\n",
    "\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BluU-6vOL9vf"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "src_folder = Path('/content/drive/MyDrive/OC_IA/P07')\n",
    "\n",
    "# Save to CSV file\n",
    "model_results.to_csv(src_folder / 'p7_03_model_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKNy4yEIpTwU"
   },
   "source": [
    "## <font color=green>P2.7 - Get experiment link for presentation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HieQUlXsTMir"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Install azure ml SDK\n",
    "!pip install azureml-core\n",
    "# !pip install azureml-pipeline\n",
    "# !pip install azureml-pipeline-core\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxxtdUlJTRzE",
    "outputId": "8cfc1cad-5663-4513-9a97-68eba14ef2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.27.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kDJZO3R7VjK6"
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Connect to workspace\n",
    "ws = Workspace.from_config('/content/drive/MyDrive/OC_IA/P07/p7_05_ws_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BZrk-EtV0Dn",
    "outputId": "7b3d6b07-24e8-4d2a-da25-aa523bc2266e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Experiment(Name: tweet-sentiment,\n",
       " Workspace: p7-workspace)]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "# Get a list of all Experiment object in a Workspace\n",
    "list_experiments = Experiment.list(ws)\n",
    "list_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "id": "WA4TQGf8XYkt",
    "outputId": "90504a82-7740-4af2-8da8-9c938e1af06d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>tweet-sentiment</td><td>df8dfd90-98a6-47e6-a8e1-8ea1b475e467</td><td>azureml.PipelineRun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/df8dfd90-98a6-47e6-a8e1-8ea1b475e467?wsid=/subscriptions/707e32d3-9ddb-48cb-96e5-2f846d6bc387/resourcegroups/oc-parcours-ia-p7/workspaces/p7-workspace&amp;tid=30a71d78-39c2-4985-a358-f813381202c6\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: tweet-sentiment,\n",
       "Id: df8dfd90-98a6-47e6-a8e1-8ea1b475e467,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieved from Azure Machine Learning web UI\n",
    "run_id = 'df8dfd90-98a6-47e6-a8e1-8ea1b475e467'\n",
    "exp = ws.experiments['tweet-sentiment']\n",
    "run = next(run for run in exp.get_runs() if run.id == run_id)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqfpmeS13n48"
   },
   "source": [
    "# <font color=salmon>CONCLUSION</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ag94MlzL3q__"
   },
   "source": [
    "From our point of view, this tool does not keep its promises : it is supposed to be straightforward, BUT IT IS NOT AT ALL.\n",
    "\n",
    "We have to admit that Microsoft lacks in pedagogy and it has trouble presenting his tutorials in a sequential manner, keeping in mind the context in which the tool is used.\n",
    "\n",
    "That's being said, we have better results than in Sentiment API, which had the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "irgkSQF8q7Nh",
    "outputId": "602f48f6-e979-4c0e-80b7-ca17ca3aa5f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model</th>\n",
       "      <th>Predict_time</th>\n",
       "      <th>AUC_Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Original tweets</td>\n",
       "      <td>212.5</td>\n",
       "      <td>71.081%</td>\n",
       "      <td>70.860%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cleaned tweets</td>\n",
       "      <td>197.2</td>\n",
       "      <td>76.187%</td>\n",
       "      <td>76.148%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lemmatized tweets</td>\n",
       "      <td>198.2</td>\n",
       "      <td>74.595%</td>\n",
       "      <td>74.633%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Model  Predict_time AUC_Score Accuracy\n",
       "0           0    Original tweets         212.5   71.081%  70.860%\n",
       "1           1     Cleaned tweets         197.2   76.187%  76.148%\n",
       "2           2  Lemmatized tweets         198.2   74.595%  74.633%"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load result\n",
    "results1 = pd.read_csv(src_folder / 'p7_02_model_results.csv')\n",
    "results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5TyMuEHq9U8"
   },
   "source": [
    "At this stage, the AML Studio models seem to give better results, especially the N--grams extraction one, especially with **84,20%** AUC but the **76,30%** Accuracy is close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "iRo_FGt2rLn1",
    "outputId": "3f1de15e-f744-4d81-c0a2-87cc0222e5c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model</th>\n",
       "      <th>Predict_time</th>\n",
       "      <th>AUC_Score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Studio - Feat. hashing</td>\n",
       "      <td>81.5</td>\n",
       "      <td>76.900%</td>\n",
       "      <td>70.000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Studio - N-grams extraction</td>\n",
       "      <td>103.4</td>\n",
       "      <td>84.200%</td>\n",
       "      <td>76.300%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        Model  Predict_time AUC_Score Accuracy\n",
       "0           0       Studio - Feat. hashing          81.5   76.900%  70.000%\n",
       "1           1  Studio - N-grams extraction         103.4   84.200%  76.300%"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load result\n",
    "results2 = pd.read_csv(src_folder / 'p7_03_model_results.csv')\n",
    "results2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "p7_03_aml_studio.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
